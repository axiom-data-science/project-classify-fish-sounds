{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "781757d7-3bcb-4ba2-bb1b-8b16494dc4c5",
   "metadata": {},
   "source": [
    "# Train a ResNet based fish (grouper) detection model\n",
    "\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook was used to create a fish (grouper) detection model trained on labeled data provided by Jim Locasio, Max Fullmer, and others from the Mote Lab.\n",
    "\n",
    "The model, a ResNet based CNN, is trained on spectrograms of twenty second audio files identified as containing a vocalization by a fish.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7022b66c-6ca3-4ff2-9e47-90b4704fecea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import fastai\n",
    "import fastai.vision.all as fai_vision\n",
    "import pandas as pd\n",
    "import fastai.callback.all as fai_callback\n",
    "import fastai.callback.tensorboard as tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1ec87a-e34f-4c90-8684-ea5cdf84b8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__, fastai.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00f3d0e-e401-408f-b32f-a0431e696e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device('cuda:3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eab9f7d-a5bd-4b2f-9430-33f7813c63cd",
   "metadata": {},
   "source": [
    "## Prepare data loader for training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b73374b-d982-4d10-9138-c7eb91d59269",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('/mnt/store/data/assets/black-grouper/data/training/spec/all-wave-samples_snr-1-whole')\n",
    "image_files = data_dir.glob('**/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c87b0b-be6a-493a-89ba-829edfd700cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of sample files to create the training set\n",
    "# Only include samples:\n",
    "# - Are not cut off or overlap (i.e. \"clean\")\n",
    "# - Include 'call-0' -> lack of call, just evironmental noise\n",
    "labels = {}\n",
    "\n",
    "for image_file in image_files:\n",
    "    if 'clean' not in str(image_file) and 'call-0' not in str(image_file):\n",
    "        continue\n",
    "    \n",
    "    # get \"call-*\" from path\n",
    "    # split out int ~ needs to be int to be a Tensor type\n",
    "    try:\n",
    "        labels[str(image_file)] = int(str(image_file.parent).split('/')[-2].split('-')[-1])\n",
    "    except:\n",
    "        labels[str(image_file)] = 0\n",
    "    \n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9359082e-b2b2-4afe-bae0-7d49a6c6567a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put data in a DataFrame to ease training setup\n",
    "df = pd.DataFrame({'fname': labels.keys(), 'label': labels.values()})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98dd2e0-e7c6-46f9-a714-c548a77352bd",
   "metadata": {},
   "source": [
    "### Distribution of classes\n",
    "\n",
    "The labels are severely unbalanced.  There are three general ways to handle this:\n",
    "\n",
    "- Just use the unbalanced classes\n",
    "- Draw equal number of samples from every class (would severely limit training size)\n",
    "- Create synthetic data to make equal class sample sizes\n",
    "\n",
    "Here, we undersample the classes with many samples and oversample classes with few examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9f2fe8-344f-49c9-af89-cc1982313462",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('label').count().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fe5309-3b3e-48cb-a274-cc0df0146e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd28a59-1268-4306-922a-0256b5e522dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to True, or remove to recreate sample\n",
    "if False:\n",
    "    df_sub = df.groupby('label').sample(n=50, replace=True)\n",
    "    df_sub.to_csv('fish-sounds-resnet101-balanced-samples-n50.csv', index=False)\n",
    "else:\n",
    "    df_sub = pd.read_csv('fish-sounds-resnet101-balanced-samples-n50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3457be16-4168-4e7f-9a95-80083fa9a39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86621a6a-6afd-49b8-b862-7fde606713c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_pct: 20% of samples are for testing\n",
    "# fn_col: column in DF that contains file name\n",
    "# label_col: column in DF with labels\n",
    "# num_workers:  Number of threads used for loading data.\n",
    "# - This is implemented using /dev/shmem and is currently a default low value.\n",
    "# - Keep as num_workers = 1\n",
    "loader = fai_vision.ImageDataLoaders.from_df(\n",
    "    df_sub,\n",
    "    path='/',\n",
    "    valid_pct=0.2,\n",
    "    seed=666,\n",
    "    fn_col=0,\n",
    "    label_col=1,\n",
    "    num_workers=1,\n",
    "    bs=16\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb37375c-1560-429b-8768-daaa5d1d1348",
   "metadata": {},
   "source": [
    "### Check out some samples\n",
    "\n",
    "Very nice feature of fastai.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01581f47-0817-4099-85f5-712718371fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader.show_batch(nrows=3, ncols=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c249fb7-2b1a-4618-8599-06a74e33d9d3",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "- ResNet101 trained on ImageNet\n",
    "- Use accuracy for model\n",
    "- Do adjust learning parameters\n",
    "- Training for ~25 epochs is fast and results in reasonable results (high 80s accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfb8044-28ad-4a3e-9bd8-ace3de36114d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "model = fai_vision.cnn_learner(\n",
    "    loader,\n",
    "    fai_vision.resnet101,\n",
    "    metrics=fai_vision.accuracy,\n",
    "    normalize=True,  # Nice touch, this normalizes inputs to aid in training.  Other libs won't do this for you.\n",
    "    pretrained=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee7332d-a395-4037-8d70-1643b9101de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "model.fine_tune(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ccefd9-d924-443c-b56e-c81d5cd0cd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.path, basepath for exporting model, defaults to '/' which has perms issues\n",
    "model.path = Path('.')\n",
    "model.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fced9ed3-4104-409f-9cea-897946620fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.export(fname='fish-sounds-resnet101-balanced-samples-n50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2594fe3a-3e8e-4126-80eb-c0b9c7b4516d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
